# Thesis Notes

idea of the thesis is not to replicate a reward machine paper but to be of an educational resource to other mathematics master students so that they could get the idea of a reward machine and see how it is motivated without being from the field of RL or logic, i.e. be more explanatory than the papers quick rl and logic recaps and do some proofs to get them familiar with the style of reasoning, tedious calculations could be put into appendix for reference but overall proof sketches should be in the main body

## Todos

- definition/theorem package?
- run q learning on a predefined gym environment
- make plot out of log
- implement reward machine
- send professor little bits to read and discuss
- ? upload all pdfs to grok for querying
- change title in hyperref and title page
- turn off colorlinks
- add / remove only commands that are used (eg notes env)
- revise layouting and typography

## Questions

- What is the title of the thesis?
- What citation style should the thesis use?
- Should the thesis cover partially obersable RL or symbolic planning?
- Can Turing Machines (or equivalent) be used instead of DFA?
- Can natural language be used or translated into reward specification or reward machines?
- Can functional logic programming be used to specify a reward machine? See [podcast](https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy56ZW5jYXN0ci5jb20vZi9vU24xaTMxNi5yc3M/episode/ZjM2NzgwZDAtYWVjNC00N2QwLWJlYjMtNjg5ZWMzNjk2NTEy)
- Is there a measure of equivalence of reward machines? Can we learn equivalent reward machines from a given one?
- Can a reward machine be decomposed into smaller reward machines? Can these be of a "lower rank"? Could these be used for a hierarchical RL algorithm?
